{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compose is used to combined different transformations. Monrmalise will normalize the ranges to -1 to +1. (x-mean)/std\n",
    "\n",
    "mnist = MNIST(root='data', \n",
    "              train=True, \n",
    "              download=True,\n",
    "              transform=Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = mnist[0]\n",
    "\n",
    "print('label:', label)\n",
    "# print(img)\n",
    "print(img.shape)\n",
    "print(torch.min(img),torch.max(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to denormalize the image\n",
    "\n",
    "def denorm(img):\n",
    "    out = (img + 1)/2\n",
    "    return out.clamp(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_norm = denorm(img)\n",
    "plt.imshow(img_norm[0],cmap='gray')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 100\n",
    "\n",
    "dataloader = DataLoader(mnist,batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discriminator Network[](http://)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 784 #28*28\n",
    "hidden_size = 256\n",
    "\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size,hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size,hidden_size),\n",
    "    nn.LeakyReLU(0.2),    \n",
    "    nn.Linear(hidden_size,1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Generator Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 64\n",
    "\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size,hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size,hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size,image_size),\n",
    "    nn.Tanh())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing G with a random sample a 2 rows of data\n",
    "\n",
    "y = G(torch.randn(2,latent_size))\n",
    "\n",
    "gimg = denorm(y.reshape(-1,28,28).detach())\n",
    "\n",
    "plt.imshow(gimg[0],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(),lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "def train_discriminator(images):\n",
    "    fake_labels = torch.zeros(batch_size,1).to(device)\n",
    "    real_labels = torch.ones(batch_size,1).to(device)\n",
    "    \n",
    "    \n",
    "    #find real loss\n",
    "    \n",
    "    d_real_out = D(images)\n",
    "    d_real_loss = criterion(d_real_out,real_labels)\n",
    "    \n",
    "    #find fake_loss\n",
    "    z = torch.randn(batch_size,latent_size).to(device)\n",
    "    fake_images = G(z)\n",
    "    d_fake_out = D(fake_images)\n",
    "    d_fake_loss = criterion(d_fake_out,fake_labels)\n",
    "    \n",
    "    \n",
    "    d_loss = d_real_loss + d_fake_loss\n",
    "    \n",
    "    reset_grad()\n",
    "    \n",
    "    d_loss.backward()\n",
    "    \n",
    "    d_optimizer.step()\n",
    "    \n",
    "    \n",
    "    return d_loss, d_real_out, d_fake_out\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = torch.optim.Adam(G.parameters(),learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    \n",
    "    x = torch.randn(batch_size,latent_size).to(device)\n",
    "    \n",
    "    fake_images = G(x)\n",
    "    labels = torch.ones(batch_size,1).to(device)\n",
    "    \n",
    "    g_loss = criterion(D(fake_images),labels)\n",
    "    \n",
    "    reset_grad()\n",
    "    g_loss.backward()\n",
    "    \n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return g_loss, fake_images\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a Samples directory\n",
    "\n",
    "import os\n",
    "\n",
    "sample_dir = 'samples'\n",
    "\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "else:\n",
    "    print(\"directory already exists\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a real image\n",
    "from IPython.display import Image\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "#save the first batch of images\n",
    "\n",
    "for images,_ in dataloader:\n",
    "    print(images.shape)\n",
    "    images = images.reshape(images.size(0),1,28,28)\n",
    "    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'), nrow=10)\n",
    "    break\n",
    "    \n",
    "Image(os.path.join(sample_dir, 'real_images.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save generator output images after each epoch, passing the same sample latent vector\n",
    "\n",
    "sample_vectors = torch.randn(batch_size, latent_size).to(device)\n",
    "\n",
    "def save_fake_images(index):\n",
    "    fake_images = G(sample_vectors)\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
    "    print('Saving', fake_fname)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=10)\n",
    "    \n",
    "# Before training\n",
    "save_fake_images(0)\n",
    "Image(os.path.join(sample_dir, 'fake_images-0000.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "\n",
    "num_epochs = 300\n",
    "total_step = len(dataloader)\n",
    "\n",
    "d_losses, g_losses, real_scores, fake_scores = [],[],[],[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (img,_) in enumerate(dataloader):\n",
    "        \n",
    "        img = img.reshape(batch_size,-1).to(device)\n",
    "        \n",
    "        d_loss,real_score, fake_score = train_discriminator(img)\n",
    "        \n",
    "        g_loss,fake_img = train_generator()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "            real_scores.append(real_score.mean().item())\n",
    "            fake_scores.append(fake_score.mean().item())\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "        \n",
    "# Sample and save images\n",
    "    save_fake_images(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoints \n",
    "torch.save(G.state_dict(), 'G.ckpt')\n",
    "torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the images\n",
    "\n",
    "Image('./samples/fake_images-0025.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the images\n",
    "\n",
    "Image('./samples/fake_images-0125.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the images\n",
    "\n",
    "Image('./samples/fake_images-0200.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the images\n",
    "\n",
    "Image('./samples/fake_images-0300.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### combine the images to a video\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "vid_fname = 'gans_training.avi'\n",
    "\n",
    "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in f]\n",
    "files.sort()\n",
    "\n",
    "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 8, (302,302))\n",
    "[out.write(cv2.imread(fname)) for fname in files]\n",
    "out.release()\n",
    "FileLink('gans_training.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the losses\n",
    "\n",
    "plt.plot(d_losses, '-')\n",
    "plt.plot(g_losses, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.title('Losses');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scores\n",
    "\n",
    "plt.plot(real_scores, '-')\n",
    "plt.plot(fake_scores, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score')\n",
    "plt.legend(['Real Score', 'Fake score'])\n",
    "plt.title('Scores');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
